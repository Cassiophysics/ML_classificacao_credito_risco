# Machine Learning - Classifica√ß√£o do Risco de Cr√©dito

![capa_ml_rlg](https://github.com/Cassiophysics/ML_classificacao_credito_risco/assets/108491443/9e460f0f-ae4b-467f-b722-ad6a06bf1b5f)

## Teste voc√™ mesmo o modelo: [üí≥ SISTEMA DE APROVA√á√ÉO DE EMPR√âSTIMOS](https://cassiophysics-ml-classificacao-credito-risc-streamlitapp-8jj1cb.streamlit.app/)

Este √© um projeto de Machine Learning de aprendizado supervisionado que visa a elabora√ß√£o de um modelo capaz de classificar quando um empr√©stimo foi bom e quando foi ruim.  Para tal finalidade, o conjunto de dados utilizado foi obtido a partir do site [KAGGLE](https://www.kaggle.com/datasets/uciml/german-credit), mas tamb√©m pode ser encontrado em  [UCI](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)). Este Dataset cont√©m uma gama de atributos de clientes a fim de se prever o risco do empr√©stimo.

Neste projeto foi feito o uso de Pipelines para dar maior legibilidade ao c√≥digo, facilitar a leitura do c√≥digo, for√ßar a execu√ß√£o das transforma√ß√µes na ordem correta e tornar o script mais reproduz√≠vel. E as m√©tricas definidas para a escolha do modelo mais adequado foram:

- Maior valor de recall
- Maior valor de f1-score
- A diferen√ßa entre falsos positivos e falsos negativos n√£o ser acima de 50, de modo a manter um certo equil√≠brio.

Assim, o racioc√≠nio utilizado para este empreendimento foi sistematizado em:

**1. An√°lise Explorat√≥ria**

Nesta etapa foi utilizado com conjunto de t√©cnicas como, por exemplo, gr√°ficos e tabelas com o intuito de tentar compreender os dados e os seus padr√µes de uma maneira mais profunda. Esta √© uma etapa importante no processo de an√°lise de dados, pois permite a gera√ß√£o de insights valiosos sobre os dados e tamb√©m verificar se os dados est√£o aptos para serem usados para responder o problema de neg√≥cio em quest√£o. Neste projeto, atrav√©s da an√°lise explorat√≥ria feita foi poss√≠vel constatar que o Dataset utilizado n√£o cont√©m valores duplicados, mas possui valores nulos e outliers, assim como diversas rela√ß√µes diferentes entre os atributos.

**2. Pr√©-processamento**

Dados sujos ou imprecisos podem levar a resultados incorretos, ou enganosos, por isso o pr√©-processamento dos dados √© uma etapa importante, pois tem como intuito realizar procedimentos para garantir que os dados estejam prontos para a elabora√ß√£o dos modelos de machine learning e que os resultados sejam confi√°veis. √Ä vista disso, fizemos o tratamento de valores nulos preenchendo pelo valor mais frequente no conjunto de dados, porque as colunas que continham valores ausentes eram categ√≥ricas, tamb√©m realizamos a padroniza√ß√£o dos dados convertendo para a mesma escala e a codifica√ß√£o das colunas categ√≥ricas.

**3. Tentativa de Tratamento do Desbalanceamento das Classes com Diferentes Pesos**

Foi testado diferentes valores de pesos para a classe de menor frequ√™ncia, que no caso √© a de empr√©stimos ruins, tendo em vista encontrar os melhores resultados conforme as m√©tricas pr√©-definidas. Primeiro verificamos com Class Weight = 'balanced' nos algoritmos que possuem este par√¢metro, em seguida foi utilizando GridSearchCV para encontrar o melhor peso, e por fim fizemos um loop testando diversos pesos diferentes.

**4. Tentativa de Tratamento do Desbalanceamento das Classes com SMOTE**

Ao ter conjuntos de dados com classes desbalanceadas pode-se levar a modelos de machine learning com desempenho ruim para a classe minorit√°ria. Diante disso, foi utilizada a t√©cnica SMOTE que prop√µe criar exemplos sint√©ticos da classe minorit√°ria, no qual funciona selecionando exemplos da classe minorit√°ria e encontra o k-√©simo vizinho mais pr√≥ximo para cada um deles. Em seguida, ele cria um exemplo sint√©tico no espa√ßo de caracter√≠sticas, colocando-o a meio caminho entre o exemplo selecionado e seu vizinho mais pr√≥ximo. Isso √© repetido at√© que a classe minorit√°ria tenha o mesmo tamanho da classe majorit√°ria. Isto posto, √© importante ter em mente que em alguns casos o SMOTE pode levar a uma perda de precis√£o e a um overfitting do modelo. No nosso caso, a t√≠tulo de exemplo, o tratamento de desbalanceamento testando diferentes pesos disp√¥s de melhores resultados comparado com o SMOTE.

**5. Otimiza√ß√£o de Hiperpar√¢metros**

A otimiza√ß√£o de hiperpar√¢metros √© importante porque diferentes conjuntos de hiperpar√¢metros podem resultar em modelos com desempenhos significativamente melhores. Al√©m disso, os hiperpar√¢metros podem afetar a velocidade do treinamento do modelo e a capacidade de generaliza√ß√£o do modelo para novos dados. Para tal finalidade, foi utilizado GridSearchCV e RandomizedSearchCV para obter os hiperpar√¢metros mais adequados. Entretanto, como tivemos que definir uma √∫nica m√©trica previamente, os melhores hiperpar√¢metros encontrados consideram somente essa m√©trica, o que n√£o leva aos melhores resultados segundo os crit√©rios definidos neste projeto.

___

**Resultado Final:** Conforme os crit√©rios que definimos, o modelo baseline LogisticRegression com peso 3.22 para a classe 1, apresentou o melhor resultado, com recall 0.80, f1-score 0.59, diferen√ßa entre falsos positivos e falsos negativos, igual a 50 e uma acur√°cia de 0.61. Ou seja, de todos os empr√©stimos presentes na amostra que realmente foram ruins (Falsos Negativos) nosso modelo conseguiu acertar 80%, mas tamb√©m manteve um n√∫mero razo√°vel de empr√©stimos bons classificados erroneamente como ruins (Falsos Positivos). A escolha do modelo ideal deve ser feita conforme as m√©tricas de neg√≥cio estabelecidas. Se o custo de perder um empr√©stimo ruim supera em muito o custo de cancelar v√°rios empr√©stimos leg√≠timos, ou seja, falsos positivos, talvez possamos escolher um peso que nos d√™ uma taxa de recall mais alta. Isso ocorre porque aumentamos nossa pontua√ß√£o de recall de maus empr√©stimos √† custa de mais casos leg√≠timos mal classificados.


